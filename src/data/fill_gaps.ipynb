{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "from xgbimputer import XGBImputer\n",
    "\n",
    "import pickle as pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open the data\n",
    "train_df = pd.read_csv('../../data/raw/train.csv')\n",
    "test_df = pd.read_csv('../../data/raw/test.csv')\n",
    "\n",
    "# save the length of the train data\n",
    "ntrain = train_df.shape[0]\n",
    "\n",
    "# concatenate the data\n",
    "data = pd.concat([train_df, test_df], ignore_index=True)\n",
    "del train_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>SeriousDlqin2yrs</th>\n",
       "      <th>RevolvingUtilizationOfUnsecuredLines</th>\n",
       "      <th>age</th>\n",
       "      <th>NumberOfTime30-59DaysPastDueNotWorse</th>\n",
       "      <th>DebtRatio</th>\n",
       "      <th>MonthlyIncome</th>\n",
       "      <th>NumberOfOpenCreditLinesAndLoans</th>\n",
       "      <th>NumberOfTimes90DaysLate</th>\n",
       "      <th>NumberRealEstateLoansOrLines</th>\n",
       "      <th>NumberOfTime60-89DaysPastDueNotWorse</th>\n",
       "      <th>NumberOfDependents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.034949</td>\n",
       "      <td>59.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004933</td>\n",
       "      <td>7959.688894</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.155308</td>\n",
       "      <td>47.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>881.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.165166</td>\n",
       "      <td>62.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.020327</td>\n",
       "      <td>2851.722407</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010886</td>\n",
       "      <td>61.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.642979</td>\n",
       "      <td>1115.657341</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000717</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3603.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  SeriousDlqin2yrs  RevolvingUtilizationOfUnsecuredLines   age  \\\n",
       "0           0               0.0                              0.034949  59.0   \n",
       "1           1               0.0                              0.155308  47.0   \n",
       "2           2               0.0                              0.165166  62.0   \n",
       "3           3               0.0                              0.010886  61.0   \n",
       "4           4               0.0                              0.000717  49.0   \n",
       "\n",
       "   NumberOfTime30-59DaysPastDueNotWorse    DebtRatio  MonthlyIncome  \\\n",
       "0                                   0.0     0.004933    7959.688894   \n",
       "1                                   0.0   881.000000            NaN   \n",
       "2                                   1.0     0.020327    2851.722407   \n",
       "3                                   0.0     0.642979    1115.657341   \n",
       "4                                   0.0  3603.000000            NaN   \n",
       "\n",
       "   NumberOfOpenCreditLinesAndLoans  NumberOfTimes90DaysLate  \\\n",
       "0                              5.0                      0.0   \n",
       "1                              6.0                      0.0   \n",
       "2                              8.0                      0.0   \n",
       "3                              6.0                      0.0   \n",
       "4                             15.0                      0.0   \n",
       "\n",
       "   NumberRealEstateLoansOrLines  NumberOfTime60-89DaysPastDueNotWorse  \\\n",
       "0                           0.0                                   0.0   \n",
       "1                           1.0                                   0.0   \n",
       "2                           0.0                                   0.0   \n",
       "3                           1.0                                   0.0   \n",
       "4                           3.0                                   0.0   \n",
       "\n",
       "   NumberOfDependents  \n",
       "0                 0.0  \n",
       "1                 0.0  \n",
       "2                 0.0  \n",
       "3                 0.0  \n",
       "4                 0.0  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0                                  0\n",
       "SeriousDlqin2yrs                        37500\n",
       "RevolvingUtilizationOfUnsecuredLines        0\n",
       "age                                         0\n",
       "NumberOfTime30-59DaysPastDueNotWorse        0\n",
       "DebtRatio                                   0\n",
       "MonthlyIncome                           29731\n",
       "NumberOfOpenCreditLinesAndLoans             0\n",
       "NumberOfTimes90DaysLate                     0\n",
       "NumberRealEstateLoansOrLines                0\n",
       "NumberOfTime60-89DaysPastDueNotWorse        0\n",
       "NumberOfDependents                       3924\n",
       "dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_impute = data.copy()\n",
    "\n",
    "# remove the columns\n",
    "columns = ['Unnamed: 0', 'SeriousDlqin2yrs']\n",
    "data_to_impute.drop(columns, axis=1, inplace=True)\n",
    "\n",
    "# calculate number of missing values by column\n",
    "missing = data_to_impute.isna().sum() \n",
    "\n",
    "# drop missing values\n",
    "data_to_impute.dropna(inplace=True)\n",
    "\n",
    "# split the data into train and test\n",
    "X_test = data_to_impute.copy().values\n",
    "\n",
    "# create a boolean array of the size of the data\n",
    "mask = np.zeros(X_test.shape, dtype=bool)\n",
    "\n",
    "for i in range(X_test.shape[1]):\n",
    "    n_missing = missing.iloc[i]\n",
    "\n",
    "    # randomly select n_missing indexes for the column\n",
    "    idx = np.random.choice(X_test.shape[0], n_missing, replace=False)\n",
    "    mask[idx, i] = True\n",
    "\n",
    "# create the train data\n",
    "X_train = np.copy(X_test)\n",
    "X_train[mask] = np.nan\n",
    "\n",
    "del data_to_impute"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the indices of the columns with missing values\n",
    "missing_idx = np.where(np.sum(mask, axis=0) > 0)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# impute the data with the simple imputer\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "\n",
    "X_train_imputed = imputer.fit_transform(X_train.copy())\n",
    "\n",
    "# create a dataframe to store the metrics\n",
    "columns_of_df = [f'mae_{i}' for i in missing_idx] + [f'mse_{i}' for i in missing_idx]\n",
    "metrics = pd.DataFrame(columns=columns_of_df)\n",
    "\n",
    "# calculate mae and mse for the imputed data for each column in the missing_idx\n",
    "for i in missing_idx:\n",
    "    mae = np.mean(np.abs(X_train_imputed[mask[:, i], i] - X_test[mask[:, i], i]))\n",
    "    mse = np.mean((X_train_imputed[mask[:, i], i] - X_test[mask[:, i], i])**2)\n",
    "\n",
    "    metrics.loc['SimpleImputer', f'mae_{i}'] = mae\n",
    "    metrics.loc['SimpleImputer', f'mse_{i}'] = mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     mae_4    mae_9             mse_4     mse_9\n",
      "SimpleImputer  3485.852782  0.91753  220723944.015543  1.274156\n"
     ]
    }
   ],
   "source": [
    "print(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iterative Imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # try load the iterative imputer with pickle\n",
    "    with open('../../models/impute/iterative_imputer.pkl', 'rb') as f:\n",
    "        imputer = pkl.load(f)\n",
    "\n",
    "except:\n",
    "    # impute the data with the iterative imputer\n",
    "    imputer = IterativeImputer(max_iter=10000, random_state=0)\n",
    "\n",
    "    # fit the imputer\n",
    "    imputer.fit(X_train.copy())\n",
    "\n",
    "    # save the imputer with pickle\n",
    "    with open('../../models/impute/iterative_imputer.pkl', 'wb') as f:\n",
    "        pkl.dump(imputer, f)\n",
    "\n",
    "X_train_imputed = imputer.transform(X_train.copy())\n",
    "\n",
    "# for each column in the missing_idx calculate the mae and mse\n",
    "for i in missing_idx:\n",
    "    mae = np.mean(np.abs(X_train_imputed[mask[:, i], i] - X_test[mask[:, i], i]))\n",
    "    mse = np.mean((X_train_imputed[mask[:, i], i] - X_test[mask[:, i], i])**2)\n",
    "\n",
    "    metrics.loc['IterativeImputer', f'mae_{i}'] = mae\n",
    "    metrics.loc['IterativeImputer', f'mse_{i}'] = mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN Imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # try load the knn imputer with pickle\n",
    "    with open('../../models/impute/knn_imputer.pkl', 'rb') as f:\n",
    "        imputer = pkl.load(f)\n",
    "\n",
    "    # try load the imputed data with pickle\n",
    "    with open('../../data/processed/knn_imputed.pkl', 'rb') as f:\n",
    "        X_train_imputed = pkl.load(f)\n",
    "except:\n",
    "    # impute the data with the knn imputer\n",
    "    imputer = KNNImputer(n_neighbors=5)\n",
    "\n",
    "    # fit the imputer\n",
    "    imputer.fit(X_train.copy())\n",
    "\n",
    "    # save the imputer with pickle\n",
    "    with open('../../models/impute/knn_imputer.pkl', 'wb') as f:\n",
    "        pkl.dump(imputer, f)\n",
    "\n",
    "    # save the imputed data\n",
    "    with open('../../data/processed/knn_imputed.pkl', 'wb') as f:\n",
    "        pkl.dump(X_train_imputed, f)\n",
    "\n",
    "# for each column in the missing_idx calculate the mae and mse\n",
    "for i in missing_idx:\n",
    "    mae = np.mean(np.abs(X_train_imputed[mask[:, i], i] - X_test[mask[:, i], i]))\n",
    "    mse = np.mean((X_train_imputed[mask[:, i], i] - X_test[mask[:, i], i])**2)\n",
    "\n",
    "    metrics.loc['KNNImputer', f'mae_{i}'] = mae\n",
    "    metrics.loc['KNNImputer', f'mse_{i}'] = mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        mae_4     mae_9             mse_4     mse_9\n",
      "SimpleImputer     3485.852782   0.91753  220723944.015543  1.274156\n",
      "IterativeImputer  3090.039388  0.871028  216601837.981775  1.195354\n",
      "KNNImputer         829.578368  0.021721  128680176.844073  0.023727\n"
     ]
    }
   ],
   "source": [
    "print(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_xgboost(X, y, space, scoring, n_estimators=250, balance=False):\n",
    "    \n",
    "    # define evaluation\n",
    "    cv = RepeatedKFold(n_splits=5, n_repeats=3, random_state=1)\n",
    "\n",
    "    # define the model\n",
    "    model = XGBRegressor(n_estimators=n_estimators, device='cuda')\n",
    "\n",
    "    # define search\n",
    "    search = RandomizedSearchCV(model, space, scoring=scoring, n_jobs=-1, cv=cv, n_iter=100)\n",
    "    \n",
    "    # execute search\n",
    "    result = search.fit(X, y)\n",
    "    \n",
    "    # plot results\n",
    "    results_df = pd.DataFrame(result.cv_results_)\n",
    "    for key, values in space.items():\n",
    "        \n",
    "        # group the results by the hyperparameter\n",
    "        param_means = []\n",
    "        param_stds = []\n",
    "        for value in values:\n",
    "            mask = results_df['param_' + key] == value\n",
    "            param_means.append(np.mean(results_df[mask]['mean_test_score']))\n",
    "            param_stds.append(np.std(results_df[mask]['mean_test_score']))\n",
    "        \"\"\"\n",
    "        # create plot with two subplots side by side\n",
    "        fig, ax = plt.subplots(1, 2, figsize=(12, 5))\n",
    "        fig.suptitle(key)\n",
    "        ax[0].plot(values, param_means)\n",
    "        ax[0].set_title('Mean test scores')\n",
    "        ax[0].set_xlabel(key)\n",
    "        ax[0].set_ylabel('mean scores')\n",
    "        padding = 0.1\n",
    "        ax[0].set_ylim(max(0, min(param_means) - padding), min(1, max(param_means) + padding))\n",
    "\n",
    "        ax[1].plot(values, param_stds)\n",
    "        ax[1].set_title('Mean score std')\n",
    "        ax[1].set_xlabel(key)\n",
    "        ax[1].set_ylabel('score std')\n",
    "        padding = 0.05\n",
    "        ax[1].set_ylim(max(0, min(param_stds) - padding), min(1, max(param_stds) + padding))\n",
    "\n",
    "        plt.show()\"\"\"\n",
    "\n",
    "    # summarize result\n",
    "    print('Best Score: %s' % result.best_score_)\n",
    "    print('Best Hyperparameters:')\n",
    "    for k, v in result.best_params_.items():\n",
    "        print('%s: %s' % (k, v))\n",
    "\n",
    "    # best model\n",
    "    best_model = result.best_estimator_\n",
    "\n",
    "    return result.best_params_, best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: -184040234.49742836\n",
      "Best Hyperparameters:\n",
      "subsample: 0.5\n",
      "reg_lambda: 0.05\n",
      "reg_alpha: 0\n",
      "gamma: 5\n",
      "3924\n",
      "Best Score: -1.07458968222369\n",
      "Best Hyperparameters:\n",
      "subsample: 1.0\n",
      "reg_lambda: 0.05\n",
      "reg_alpha: 0.001\n",
      "gamma: 5\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# find indices of the columns with missing values\n",
    "missing_idx = np.where(np.sum(mask, axis=0) > 0)[0]\n",
    "\n",
    "# define the space of hyperparameters\n",
    "space = {\n",
    "    'subsample': [0.5, 0.8, 1.0],\n",
    "    'gamma': [0, 0.5, 2, 5],\n",
    "    'reg_alpha': [0, 0.001, 0.01, 0.05],\n",
    "    'reg_lambda': [0, 0.001, 0.01, 0.05],\n",
    "}\n",
    "\n",
    "X_imputed = np.copy(X_train)\n",
    "\n",
    "for idx in missing_idx:\n",
    "    X = np.copy(X_train)\n",
    "    X = np.delete(X, idx, axis=1)\n",
    "    y = np.copy(X_imputed[:, idx])\n",
    "\n",
    "    # find the the indices of the missing values in the column\n",
    "    nan_mask = np.isnan(y)\n",
    "\n",
    "    X_train_xgboost = X[~nan_mask]\n",
    "    y_train_xgboost = y[~nan_mask]\n",
    "    X_test_xgboost = X[nan_mask]\n",
    "\n",
    "    try:\n",
    "        # try load the model with pickle\n",
    "        with open(f'../../models/impute/xgboost_{idx}.pkl', 'rb') as f:\n",
    "            best_model = pkl.load(f)\n",
    "    except:\n",
    "        # tune the model\n",
    "        best_params, model = tune_xgboost(X_train_xgboost, y_train_xgboost, space, scoring='neg_mean_squared_error', n_estimators=400)\n",
    "\n",
    "        # define new number of estimators\n",
    "        n_estimators = 20000\n",
    "\n",
    "        # add the number of estimators to the best params\n",
    "        best_params['n_estimators'] = n_estimators\n",
    "\n",
    "        # fit a new model with the best parameters\n",
    "        best_model = XGBRegressor(**best_params)\n",
    "\n",
    "        # fit the model\n",
    "        best_model.fit(X_train_xgboost, y_train_xgboost)\n",
    "\n",
    "        # save the model with pickle\n",
    "        with open(f'../../models/impute/xgboost_{idx}.pkl', 'wb') as f:\n",
    "            pkl.dump(best_model, f)\n",
    "\n",
    "    # impute the data with the xgboost imputer\n",
    "    y_pred = model.predict(X_test_xgboost)\n",
    "\n",
    "    # replace the missing values\n",
    "    X_imputed[nan_mask, idx] = y_pred\n",
    "\n",
    "    print(np.isnan(X_imputed).sum())\n",
    "\n",
    "    # for each column in the missing_idx calculate the mae and mse\n",
    "    for i in missing_idx:\n",
    "        mae = np.mean(np.abs(X_imputed[mask[:, i], i] - X_test[mask[:, i], i]))\n",
    "        mse = np.mean((X_imputed[mask[:, i], i] - X_test[mask[:, i], i])**2)\n",
    "\n",
    "        metrics.loc['XGBoostImputer', f'mae_{i}'] = mae\n",
    "        metrics.loc['XGBoostImputer', f'mse_{i}'] = mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        mae_4     mae_9             mse_4     mse_9\n",
      "SimpleImputer     3485.852782   0.91753  220723944.015543  1.274156\n",
      "IterativeImputer  3090.039388  0.871028  216601837.981775  1.195354\n",
      "KNNImputer         829.578368  0.021721  128680176.844073  0.023727\n",
      "XGBoostImputer    2837.246798  0.789816  461646645.675941  1.039176\n"
     ]
    }
   ],
   "source": [
    "print(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGB Imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # try load the xgb imputer with pickle\n",
    "    with open('../../models/impute/xgb_imputer.pkl', 'rb') as f:\n",
    "        imputer = pkl.load(f)\n",
    "\n",
    "    # try load the imputed data with pickle\n",
    "    with open('../../data/processed/xgb_imputed.pkl', 'rb') as f:\n",
    "        X_train_imputed = pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dist_with_miss(a, b, l=0.0):\n",
    "    \"\"\"\n",
    "    Calculate the distance between two arrays, taking into account missing values.\n",
    "\n",
    "    Parameters:\n",
    "    a (array-like): The first array.\n",
    "    b (array-like): The second array.\n",
    "    l (float, optional): The penalty for missing values. Defaults to 0.0.\n",
    "\n",
    "    Returns:\n",
    "    float: The distance between the two arrays.\n",
    "\n",
    "    Raises:\n",
    "    None\n",
    "\n",
    "    \"\"\"\n",
    "    if len(a) != len(b):\n",
    "        return np.inf\n",
    "    ls = l * np.ones(len(a))\n",
    "    msk = ~ (np.isnan(a) | np.isnan(b))\n",
    "    res = np.sum((np.abs(a - b)[msk])) + np.sum((ls[~msk]))\n",
    "    return res"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

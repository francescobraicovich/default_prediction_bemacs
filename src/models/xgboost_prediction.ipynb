{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "\n",
    "import pickle\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, f1_score, precision_score, recall_score, confusion_matrix\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from tune_model import tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the train data\n",
    "data = pd.read_csv('../../data/processed/engineered_features_data/train_imputed_engineered_poly.csv')\n",
    "\n",
    "# load the selected features from the .pkl file\n",
    "with open('../../data/processed/selected_features/rfecv_features_to_keep.pkl', 'rb') as f:\n",
    "    selected_features = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_use = data[selected_features]\n",
    "\n",
    "# split the data into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_to_use.drop('SeriousDlqin2yrs', axis=1), data_to_use['SeriousDlqin2yrs'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the scale_pos_weight\n",
    "scale_pos_weight = y_train.value_counts()[0] / y_train.value_counts()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the space of hyperparameters to search for xgboost\n",
    "param_space = {\n",
    "    'n_estimators': [150],\n",
    "    'max_depth': [2, 3, 5],\n",
    "    'gamma': [0],\n",
    "    'learning_rate': [0.01, 0.1],\n",
    "    'subsample': [0.6, 0.8, 1],\n",
    "    'colsample_bytree': [0.6, 0.8, 1],\n",
    "    'colsample_bylevel': [0.6, 0.8, 1],\n",
    "    'scale_pos_weight': [scale_pos_weight],\n",
    "    'objective': ['binary:logistic'],\n",
    "}\n",
    "model = XGBClassifier()\n",
    "\n",
    "# define a multi metric to use in the tuning\n",
    "scoring = {\n",
    "    'Accuracy': 'accuracy',\n",
    "    'AUC': 'roc_auc',\n",
    "    'F1': 'f1',\n",
    "    'Precision': 'precision',\n",
    "    'Recall': 'recall'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 162 candidates, totalling 810 fits\n",
      "Best Score: 0.8637367302594668\n",
      "Best Hyperparameters:\n",
      "colsample_bylevel: 0.6\n",
      "colsample_bytree: 0.8\n",
      "gamma: 0\n",
      "learning_rate: 0.1\n",
      "max_depth: 3\n",
      "n_estimators: 150\n",
      "objective: binary:logistic\n",
      "scale_pos_weight: 13.885874958650348\n",
      "subsample: 0.8\n"
     ]
    }
   ],
   "source": [
    "# tune the model\n",
    "best_params, best_model = tune(X=X_train, y=y_train, space=param_space, \n",
    "                               model=model, search_type='grid', n_iter_random=120, \n",
    "                               n_splits=5, n_repeats=1, scoring=scoring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model\n",
    "with open('../../models/xgboost_classifier.pkl', 'wb') as f:\n",
    "    pickle.dump(best_model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.792\n",
      "ROC AUC: 0.7802002844317193\n",
      "F1 score: 0.3256484149855908\n",
      "Precision: 0.20673252835711672\n",
      "Recall: 0.7666214382632293\n",
      "Confusion matrix: [[16690  4336]\n",
      " [  344  1130]]\n"
     ]
    }
   ],
   "source": [
    "# evaluate on the test set\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# print the evaluation metrics\n",
    "print(f'Accuracy: {accuracy_score(y_test, y_pred)}')\n",
    "print(f'ROC AUC: {roc_auc_score(y_test, y_pred)}')\n",
    "print(f'F1 score: {f1_score(y_test, y_pred)}')\n",
    "print(f'Precision: {precision_score(y_test, y_pred)}')\n",
    "print(f'Recall: {recall_score(y_test, y_pred)}')\n",
    "print(f'Confusion matrix: {confusion_matrix(y_test, y_pred)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
